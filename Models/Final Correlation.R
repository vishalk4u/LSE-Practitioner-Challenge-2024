#This works out a correlation matrix, applies James-Steinz to shrink the matrix, then
# filters the matrix, then sums up values and gets simple averages coefficients ie
# average over companies.

#Then uses rolling windows to get correlations over time between all pairs of symbols
# which can be seen in rolling_corr_list and corr_matrix_list. Then creates sum_matrix
# which is the average of the correlations over time, then shrunk. (Avg over time)

#Also the code calculates default probabilities and applying the same steps as 
# equity, above, to get simple averages from a 'default correlation matrix'. 
# Uses annual data, as equity corr was done on an annual basis. 

#Then same approach as above for equity average over time, instead using default
# probabilities to get 'average over time' by looking at the rolling correlations.

#Doubt: doesn't actually give log returns as if I run the function without 
# type= 'log' then I get the same returns unless it automatically works out log 
# returns? But on below website, they said type= 'log' works in Example 1B
# https://cran.r-project.org/web/packages/tidyquant/vignettes/TQ02-quant-integrations-in-tidyquant.html#example-1-use-quantmod-periodreturn-to-convert-prices-to-returns
# , so let's assume it works.

#Need a large sample size, when increase data time frame to say 2004-2020, need to 
# filter out incomplete data as was getting NA's therefore James-Steinz was not working, 
# I fixed this by replacing NA's with 0, but need a large sample size in order for 
# the shrinkage intensity to be not 1.

#To improve:
# Automate the debt_data process further by accessing some databank for debt data.

# Code might not run when the 'length of log returns' is not the same for companies, it leads 
#  to a single row+column being all 0 and a diagonal 1 entry, not a big issue as other
#  values remain therefore can ignore. So in order for lengths to be the same, need 
#  to add extrapolation.

# Add exponential weights to rolling correlation windows.

# Add a James-Steinz function to shrink the multiple individual matrices generated by 
#  corr_matrix_list, instead of just shrinking the sum_matrix.


library(tidyquant)
library(timetk)
library(tidyverse)
library(zoo)
library(padr)
library(dplyr)
library(corpcor)

# Define the function to handle missing values in correlation matrices
handle_missing_values <- function(mat) {
  # Replace NA values with 0
  mat[is.na(mat)] <- 0
  return(mat)
}

# Setting our stock symbols to a variable
tickers <- c("VALE", "PBR", "ITUB", "ABCB", "EC", "AMX", "CX","BVN","TV","YPF","MELI","BBD","BRFS","GGB","ABEV",
             "TGS","BBVA","TEO","BMA",
             "FMX",
             "CIB",
             "SCCO",
             "SQM","BAP")

# Download the stock price data
multpl_stocks <- tq_get(tickers,
                        from = "2008-01-01",
                        to = "2021-01-01",
                        get = "stock.prices")

# Remove rows with missing values from multpl_stocks.
multpl_stocks <- multpl_stocks %>%
  na.omit()

company_info <- data.frame(
  symbol = c("VALE", "PBR", "ITUB", "ABCB", "EC", "AMX", "CX","BVN","TV","YPF","MELI",
             "BBD","BRFS","GGB","ABEV",
             "TGS","BBVA","TEO","BMA",
             "FMX",
             "CIB",
             "SCCO",
             "SQM","BAP"),
  Sector = c("Agribusiness", "Energy", "Bank", "Bank", "Energy", "Telecommunications", "Construction","Environment","Telecommunications","Energy","Services",
             "Bank","Consumer","Material","Consumer",
             "Energy", "Bank", "Telecommunications", "Bank",
             "Consumer",
             "Bank",
             "Material",
             "Material","Bank"),
  Fsector = c("Non_Financial", "Non_Financial", "Financial", "Financial", "Non_Financial", "Non_Financial", "Non_Financial","Non_Financial","Non_Financial","Non_Financial","Non_Financial",
              "Financial","Non_Financial", "Non_Financial","Non_Financial",
              "Non_Financial","Financial","Non_Financial","Financial",
              "Non_Financial",
              "Financial",
              "Non_Financial",
              "Non_Financial","Financial"),
  Country = c("Brazil", "Brazil", "Brazil", "Brazil", "Colombia", "Mexico", "Mexico","Peru","Mexico","Argentina","Argentina",
              "Brazil","Brazil","Brazil","Brazil",
              "Argentina","Argentina","Argentina","Argentina",
              "Mexico",
              "Colombia",
              "Peru",
              "Chile","Chile"
  )
)

company_info

# Calculating the annual log returns for multiple stocks
multpl_stock_log_returns <- multpl_stocks %>%
  group_by(symbol) %>%
  tq_transmute(select = adjusted,
               mutate_fun = periodReturn,
               period = 'yearly', 
               type = "log",
               col_rename = 'returns')

# Find the minimum length of log returns
min_length <- multpl_stock_log_returns %>%
  group_by(symbol) %>%
  summarise(min_length = min(n()))

# Calculating the correlation
company_corr <- multpl_stock_log_returns %>%
  spread(symbol, value = returns) %>%
  tk_xts(silent = TRUE) %>%
  cor()

# Handle missing values in correlation matrices
company_corr <- handle_missing_values(company_corr)

# Print the correlation matrix
print(company_corr)

# Now we shrink the company_corr in order to bring all correlations closer to 
#some global average.

company_corr
L1<-estimate.lambda(company_corr,verbose = TRUE)
L1
adj_company_corr<-cor.shrink(company_corr,lambda =L1)
adj_company_corr

# Initialize a matrix of zeros with the same dimensions as the correlation matrix
filtered_corr_global <- matrix(0, nrow = nrow(adj_company_corr), ncol = ncol(adj_company_corr))

# Loop through each row of the correlation matrix
for (i in 1:nrow(adj_company_corr)) {
  for (j in 1:ncol(adj_company_corr)) {
    # Get the symbols of the corresponding companies
    symbol1 <- rownames(adj_company_corr)[i]
    symbol2 <- colnames(adj_company_corr)[j]
    
    # Get the country and sector information for each company
    country1 <- company_info$Country[company_info$symbol == symbol1]
    country2 <- company_info$Country[company_info$symbol == symbol2]
    sector1 <- company_info$Sector[company_info$symbol == symbol1]
    sector2 <- company_info$Sector[company_info$symbol == symbol2]
    
    # Check if the companies are from different countries and sectors
    if (country1 != country2 & sector1 != sector2) {
      # Keep the correlation value unchanged
      filtered_corr_global[i, j] <- adj_company_corr[i, j]
    }
  }
}

# Print the filtered correlation matrix
print(filtered_corr_global)

#calculate simple average ie average over companies
non_empty_cells <- sum(filtered_corr_global != 0, na.rm = TRUE)
sum_of_correlations <- sum(filtered_corr_global, na.rm = TRUE)
avg_correlation_global <- sum_of_correlations / non_empty_cells

print(avg_correlation_global)
#This is the average correlation for global i.e different country, different sector

#///////////////////////////////////////////////////////////////////////////////

#This is for average country correlation coefficient ie same country, different sector
# Initialize a matrix of zeros with the same dimensions as the correlation matrix
filtered_corr_country <- matrix(0, nrow = nrow(adj_company_corr), ncol = ncol(adj_company_corr))

# Loop through each row of the correlation matrix
for (i in 1:nrow(adj_company_corr)) {
  for (j in 1:ncol(adj_company_corr)) {
    # Get the symbols of the corresponding companies
    symbol1 <- rownames(adj_company_corr)[i]
    symbol2 <- colnames(adj_company_corr)[j]
    
    # Get the country and sector information for each company
    country1 <- company_info$Country[company_info$symbol == symbol1]
    country2 <- company_info$Country[company_info$symbol == symbol2]
    sector1 <- company_info$Sector[company_info$symbol == symbol1]
    sector2 <- company_info$Sector[company_info$symbol == symbol2]
    
    # Check if the companies are from the same country but different sectors
    if (country1 == country2 & sector1 != sector2) {
      # Keep the correlation value unchanged
      filtered_corr_country[i, j] <- adj_company_corr[i, j]
    }
  }
}

# Print the filtered correlation matrix
print(filtered_corr_country)

# Calculate the simple average correlation over non-empty cells
non_empty_cells_country <- sum(filtered_corr_country != 0, na.rm = TRUE)
sum_of_correlations_country <- sum(filtered_corr_country, na.rm = TRUE)
avg_correlation_country <- sum_of_correlations_country / non_empty_cells_country

print(avg_correlation_country)

#/////////////////////////////////////////////////////////////////////////////////////////
#The average Financial correlation Coefficient, ie same country, any financial sector
#Initialize a matrix of zeros with the same dimensions as the correlation matrix
filtered_corr_financial <- matrix(0, nrow = nrow(adj_company_corr), ncol = ncol(adj_company_corr))

# Loop through each row of the correlation matrix
for (i in 1:nrow(adj_company_corr)) {
  for (j in 1:ncol(adj_company_corr)) {
    # Get the symbols of the corresponding companies
    symbol1 <- rownames(adj_company_corr)[i]
    symbol2 <- colnames(adj_company_corr)[j]
    
    # Get the country and sector information for each company
    country1 <- company_info$Country[company_info$symbol == symbol1]
    country2 <- company_info$Country[company_info$symbol == symbol2]
    sector1 <- company_info$Sector[company_info$symbol == symbol1]
    sector2 <- company_info$Sector[company_info$symbol == symbol2]
    fsector1 <- company_info$Fsector[company_info$symbol == symbol1]
    fsector2 <- company_info$Fsector[company_info$symbol == symbol2]
    
    # Check if the companies are from the same country and belong to the financial sector
    if (symbol1 != symbol2 & country1 == country2 & fsector1 == "Financial" & fsector2 == "Financial") {
      # Keep the correlation value unchanged
      filtered_corr_financial[i, j] <- adj_company_corr[i, j]
    }
  }
}

# Print the filtered correlation matrix
print(filtered_corr_financial)

# Calculate the simple average correlation over non-empty cells
non_empty_cells_financial <- sum(filtered_corr_financial != 0, na.rm = TRUE)
sum_of_correlations_financial <- sum(filtered_corr_financial, na.rm = TRUE)
avg_correlation_financial <- sum_of_correlations_financial / non_empty_cells_financial

print(avg_correlation_financial)

#/////////////////////////////////////////////////////////////////////////////////////////////
#Non-financial correlation coefficient, same country, any non-financial sector
# Initialize a matrix of zeros with the same dimensions as the correlation matrix
filtered_corr_non_financial <- matrix(0, nrow = nrow(adj_company_corr), ncol = ncol(adj_company_corr))

# Loop through each row of the correlation matrix
for (i in 1:nrow(adj_company_corr)) {
  for (j in 1:ncol(adj_company_corr)) {
    # Get the symbols of the corresponding companies
    symbol1 <- rownames(adj_company_corr)[i]
    symbol2 <- colnames(adj_company_corr)[j]
    
    # Get the country and sector information for each company
    country1 <- company_info$Country[company_info$symbol == symbol1]
    country2 <- company_info$Country[company_info$symbol == symbol2]
    sector1 <- company_info$Sector[company_info$symbol == symbol1]
    sector2 <- company_info$Sector[company_info$symbol == symbol2]
    fsector1 <- company_info$Fsector[company_info$symbol == symbol1]
    fsector2 <- company_info$Fsector[company_info$symbol == symbol2]
    
    # Check if the companies are from the same country and belong to the non-financial sector
    if (symbol1 != symbol2 & country1 == country2 & fsector1 == "Non_Financial" & fsector2 == "Non_Financial") {
      # Keep the correlation value unchanged
      filtered_corr_non_financial[i, j] <- adj_company_corr[i, j]
    }
  }
}

# Print the filtered correlation matrix
print(filtered_corr_non_financial)

# Calculate the simple average correlation over non-empty cells
non_empty_cells_non_financial <- sum(filtered_corr_non_financial != 0, na.rm = TRUE)
sum_of_correlations_non_financial <- sum(filtered_corr_non_financial, na.rm = TRUE)
avg_correlation_non_financial <- sum_of_correlations_non_financial / non_empty_cells_non_financial

print(avg_correlation_non_financial)

#if says NaN, that's true as in the current 6 stocks there is no pairs that match this
#/////////////////////////////////////////////////////////////////////////

#Now for an 'average over time' for equity correlation

# Define the fixed window size
window_size <- 3

# Define a list to store the rolling correlation matrices for each window size
rolling_corr_list <- list()

# Loop through each pair of symbols
for (i in 1:(length(tickers) - 1)) {
  for (j in (i + 1):length(tickers)) {
    # Combine returns for the current pair of symbols into a single data frame
    returns_df <- merge(
      multpl_stock_log_returns %>% filter(symbol == tickers[i]),
      multpl_stock_log_returns %>% filter(symbol == tickers[j]),
      by = "date", suffixes = c(paste0("_", tickers[i]), paste0("_", tickers[j]))
    )
    
    # Convert data to zoo object for rolling calculations
    zoo_data <- zoo(returns_df[, c(paste0("returns_", tickers[i]), paste0("returns_", tickers[j]))], 
                    order.by = returns_df$date)
    
    # Calculate rolling correlation
    rolling_corr <- rollapply(zoo_data, width = window_size, function(x) cor(x[, 1], x[, 2]), by.column = FALSE)
    
    # Store the rolling correlation in the list
    corr_key <- paste(tickers[i], tickers[j], sep = "_vs_")
    rolling_corr_list[[corr_key]] <- rolling_corr
  }
}

# Print the list of rolling correlation matrices,
print(rolling_corr_list)

#You can now look here at rolling_corr_list look at a specific pair of companies equity correlations over
# time. You can stop here as your view of 'average over time'.

# Add a plot of one example between two companies to show correlation over time.
# [Plot] an example between two companies to show correlation over time.

plot(rolling_corr_list$VALE_vs_PBR,
     xlab = "3-years Window Start Date",
     ylab = "Correlation",
     main = "VALE_vs_PBR",
     type = "b")

#Now to create a matrix for every rolling correlation, to better represent these
#multiple rolling corr's at the same time, and to also workout an average of the rolling correlations.

# Define the fixed window size
window_size <- 3

# Define a list to store the rolling correlation matrices for each window size
rolling_corr_list <- list()

# Loop through each pair of symbols
for (i in 1:(length(tickers) - 1)) {
  for (j in (i + 1):length(tickers)) {
    # Combine returns for the current pair of symbols into a single data frame
    returns_df <- merge(
      multpl_stock_log_returns %>% filter(symbol == tickers[i]),
      multpl_stock_log_returns %>% filter(symbol == tickers[j]),
      by = "date", suffixes = c(paste0("_", tickers[i]), paste0("_", tickers[j]))
    )
    
    # Convert data to zoo object for rolling calculations
    zoo_data <- zoo(returns_df[, c(paste0("returns_", tickers[i]), paste0("returns_", tickers[j]))], 
                    order.by = returns_df$date)
    
    # Calculate rolling correlation
    rolling_corr <- rollapply(zoo_data, width = window_size, function(x) cor(x[, 1], x[, 2]), by.column = FALSE)
    
    # Store the rolling correlation in the list
    corr_key <- paste(tickers[i], tickers[j], sep = "_vs_")
    rolling_corr_list[[corr_key]] <- rolling_corr
  }
}

# Print the list of rolling correlation matrices
print(rolling_corr_list)

#Now to put these lists into matrices.

# Initialize an empty list to store multiple correlation matrices
corr_matrix_list <- list()

# Loop through each entry in the rolling correlation list
for (k in 1:length(rolling_corr_list)) {
  # Initialize an empty matrix to store the rolling correlation coefficients
  corr_matrix <- matrix(NA, nrow = length(tickers), ncol = length(tickers))
  rownames(corr_matrix) <- tickers
  colnames(corr_matrix) <- tickers
  
  # Loop through each pair of symbols
  for (i in 1:length(tickers)) {
    for (j in 1:length(tickers)) {
      # Define the key for accessing the rolling correlation list
      corr_key <- paste(tickers[i], tickers[j], sep = "_vs_")
      
      # Check if the rolling correlation list exists for the current pair of symbols
      if (corr_key %in% names(rolling_corr_list)) {
        # Extract the rolling correlation for the current entry from the rolling_corr_list
        rolling_corr <- rolling_corr_list[[corr_key]]
        
        # Store the rolling correlation in the matrix
        corr_matrix[i, j] <- rolling_corr[k]
      } else {
        # If no rolling correlation is available, set the corresponding matrix entry to NA
        corr_matrix[i, j] <- NA
      }
    }
  }
  
  # Append the correlation matrix to the list
  corr_matrix_list[[k]] <- corr_matrix
}

# Print the list of correlation matrices
print(corr_matrix_list)

#With this corr_matrix_list, you can now look at n-(W-1) matrixes,where n=number of 
# companies, W=window size , where each matrix contains the corresponding rolling
# correlation, You can stop here as your view of 'average over time'.

# Initialize an empty matrix to store the sum of matrices
sum_matrix <- matrix(0, nrow = length(tickers), ncol = length(tickers))

# Initialize a flag variable to track whether we've encountered the first NA matrix
encountered_na <- FALSE

# Loop through each matrix in the list
for (i in 1:(length(corr_matrix_list) - 1)) {
  # Check if the current matrix is entirely NA
  if (all(is.na(corr_matrix_list[[i]]))) {
    # If it is, set the flag variable to TRUE and break the loop
    encountered_na <- TRUE
    break
  }
  # If we haven't encountered an NA matrix yet, add the current matrix to the sum matrix
  sum_matrix <- sum_matrix + corr_matrix_list[[i]]
}

# If we encountered an NA matrix, divide the sum matrix by the number of matrices added
if (encountered_na) {
  sum_matrix <- sum_matrix / (i - 1)
} else {
  # If no NA matrix was encountered, divide by the total number of matrices
  sum_matrix <- sum_matrix / i
}

# Print the resulting sum matrix
print(sum_matrix)

#Apply at end, to complete matrix

#Add a leading diagonal of 1
diag(sum_matrix) <- 1

# Make the matrix symmetrical below the leading 1
for (i in 1:(length(tickers) - 1)) {
  for (j in (i + 1):length(tickers)) {
    sum_matrix[j, i] <- sum_matrix[i, j]
  }
}

# Print the updated final correlation matrix
print(sum_matrix)

#This sum_matrix is the average of the rolling correlations for all pairs of symbols

#Now from here we can apply the James-Steinz estimator to shrink the matrix.

L3<-estimate.lambda(sum_matrix,verbose = TRUE)
L3
shrunk_sum_matrix<-cor.shrink(sum_matrix,lambda =L3)
shrunk_sum_matrix

#Now to this shrunk_sum_matrix you can apply filtering to get identify specific
#average correlations over time eg global, country, financial, non-financial. Where
#each one is called aot_filtered_corr_type, aot=average over time.

# Initialize a matrix of zeros with the same dimensions as the correlation matrix
aot_filtered_corr_global <- matrix(0, nrow = nrow(shrunk_sum_matrix), ncol = ncol(shrunk_sum_matrix))

# Loop through each row of the correlation matrix
for (i in 1:nrow(shrunk_sum_matrix)) {
  for (j in 1:ncol(shrunk_sum_matrix)) {
    # Get the symbols of the corresponding companies
    symbol1 <- rownames(shrunk_sum_matrix)[i]
    symbol2 <- colnames(shrunk_sum_matrix)[j]
    
    # Get the country and sector information for each company
    country1 <- company_info$Country[company_info$symbol == symbol1]
    country2 <- company_info$Country[company_info$symbol == symbol2]
    sector1 <- company_info$Sector[company_info$symbol == symbol1]
    sector2 <- company_info$Sector[company_info$symbol == symbol2]
    
    # Check if the companies are from different countries and sectors
    if (country1 != country2 & sector1 != sector2) {
      # Keep the correlation value unchanged
      aot_filtered_corr_global[i, j] <- shrunk_sum_matrix[i, j]
    }
  }
}

# Print the filtered correlation matrix
print(aot_filtered_corr_global)

#This is the average correlation over time for global i.e different country, different sector

#///////////////////////////////////////////////////////////////////////////////

#This is for average country correlation coefficient ie same country, different sector
# Initialize a matrix of zeros with the same dimensions as the correlation matrix
aot_filtered_corr_country <- matrix(0, nrow = nrow(shrunk_sum_matrix), ncol = ncol(shrunk_sum_matrix))

# Loop through each row of the correlation matrix
for (i in 1:nrow(shrunk_sum_matrix)) {
  for (j in 1:ncol(shrunk_sum_matrix)) {
    # Get the symbols of the corresponding companies
    symbol1 <- rownames(shrunk_sum_matrix)[i]
    symbol2 <- colnames(shrunk_sum_matrix)[j]
    
    # Get the country and sector information for each company
    country1 <- company_info$Country[company_info$symbol == symbol1]
    country2 <- company_info$Country[company_info$symbol == symbol2]
    sector1 <- company_info$Sector[company_info$symbol == symbol1]
    sector2 <- company_info$Sector[company_info$symbol == symbol2]
    
    # Check if the companies are from the same country but different sectors
    if (country1 == country2 & sector1 != sector2) {
      # Keep the correlation value unchanged
      aot_filtered_corr_country[i, j] <- shrunk_sum_matrix[i, j]
    }
  }
}

# Print the filtered correlation matrix
print(aot_filtered_corr_country)

#/////////////////////////////////////////////////////////////////////////////////////////
#The average Financial correlation Coefficient, ie same country, any financial sector
#Initialize a matrix of zeros with the same dimensions as the correlation matrix
aot_filtered_corr_financial <- matrix(0, nrow = nrow(shrunk_sum_matrix), ncol = ncol(shrunk_sum_matrix))

# Loop through each row of the correlation matrix
for (i in 1:nrow(shrunk_sum_matrix)) {
  for (j in 1:ncol(shrunk_sum_matrix)) {
    # Get the symbols of the corresponding companies
    symbol1 <- rownames(shrunk_sum_matrix)[i]
    symbol2 <- colnames(shrunk_sum_matrix)[j]
    
    # Get the country and sector information for each company
    country1 <- company_info$Country[company_info$symbol == symbol1]
    country2 <- company_info$Country[company_info$symbol == symbol2]
    sector1 <- company_info$Sector[company_info$symbol == symbol1]
    sector2 <- company_info$Sector[company_info$symbol == symbol2]
    fsector1 <- company_info$Fsector[company_info$symbol == symbol1]
    fsector2 <- company_info$Fsector[company_info$symbol == symbol2]
    
    # Check if the companies are from the same country and belong to the financial sector
    if (symbol1 != symbol2 & country1 == country2 & fsector1 == "Financial" & fsector2 == "Financial") {
      # Keep the correlation value unchanged
      aot_filtered_corr_financial[i, j] <- shrunk_sum_matrix[i, j]
    }
  }
}

# Print the filtered correlation matrix
print(aot_filtered_corr_financial)

#/////////////////////////////////////////////////////////////////////////////////////////////
#Non-financial correlation coefficient, same country, any non-financial sector
# Initialize a matrix of zeros with the same dimensions as the correlation matrix
aot_filtered_corr_non_financial <- matrix(0, nrow = nrow(shrunk_sum_matrix), ncol = ncol(shrunk_sum_matrix))

# Loop through each row of the correlation matrix
for (i in 1:nrow(shrunk_sum_matrix)) {
  for (j in 1:ncol(shrunk_sum_matrix)) {
    # Get the symbols of the corresponding companies
    symbol1 <- rownames(shrunk_sum_matrix)[i]
    symbol2 <- colnames(shrunk_sum_matrix)[j]
    
    # Get the country and sector information for each company
    country1 <- company_info$Country[company_info$symbol == symbol1]
    country2 <- company_info$Country[company_info$symbol == symbol2]
    sector1 <- company_info$Sector[company_info$symbol == symbol1]
    sector2 <- company_info$Sector[company_info$symbol == symbol2]
    fsector1 <- company_info$Fsector[company_info$symbol == symbol1]
    fsector2 <- company_info$Fsector[company_info$symbol == symbol2]
    
    # Check if the companies are from the same country and belong to the non-financial sector
    if (symbol1 != symbol2 & country1 == country2 & fsector1 == "Non_Financial" & fsector2 == "Non_Financial") {
      # Keep the correlation value unchanged
      aot_filtered_corr_non_financial[i, j] <- shrunk_sum_matrix[i, j]
    }
  }
}

# Print the filtered correlation matrix
print(aot_filtered_corr_non_financial)

#Now after getting the sum matrix, applying James Steinz, we've successfully filtered each
#matrix to see the average correlation over time for each of the 4 types.

#/////////////////////////////////////////////////////////////////////////////////

#Setting up data for default probability calculations for default correlation

#Function to calculate Distance-to-default

dtd <- function(mcap, debt, vol, r){
  if(debt==0) stop("Please provide a non-zero debt value")
  stopifnot(is.numeric(mcap),
            is.numeric(debt),
            is.numeric(vol),
            is.numeric(r))
  
  rho <- 1                 # forbearance
  Maturity <- 1
  
  ## Starting values of firm's market value and its volatility
  seed.V <- mcap + debt
  seed.sV <- mcap * vol / debt
  
  # Present value of debt
  debt <- debt * exp(-r)
  
  # Solving reverse Black-Scholes for market value of asset and
  # asset volatility  
  d1 <- function(V, debt, sV, Maturity) {
    num <- log(V/debt) + 0.5*sV*sV*Maturity
    den <- sV * sqrt(Maturity)
    num/den
  }
  
  d2 <- function(V, debt, sV, Maturity) {
    d1(V, debt, sV, Maturity) - sV*sqrt(Maturity)
  }
  
  
  ## Feed this function the parameter vector x.
  ## Error term computation:
  ## It returns the sum of squared errors for the two equations
  ## x[1] is V and x[2] is sV. 
  
  objective.function <- function(x, mcap, vol, debt, rho, Maturity){
    
    e1 <- -mcap + x[1]*pnorm(d1(x[1], debt*rho, x[2], Maturity)) -
      rho*debt*pnorm(d2(x[1], rho*debt, x[2], Maturity))
    
    e2 <- -vol*mcap + x[2]*x[1]*pnorm(d1(x[1], debt*rho, x[2], Maturity))
    
    (e1*e1) + (e2*e2)
  }
  
  # Solve it - Minimizing the error term
  res <- optim(c(seed.V, seed.sV),
               method="L-BFGS-B",
               fn=objective.function,
               lower=c(mcap, 0), upper=c(Inf, Inf),
               mcap=mcap, vol=vol, debt=debt, Maturity=Maturity,
               rho=rho)
  
  # Distance-to-default calculation
  dtd.v <- (res$par[1] - debt)/(res$par[1]*res$par[2])
  
  # Probability of default calculation
  pd <- pnorm(-dtd.v)
  
  return(list("dtd.v"=dtd.v, "asset.v"=res$par[1], "sigma.v"=res$par[2], "pd"=pd))
}

#Now to data.
# Aggregate data to yearly level, to get yearly adjusted prices and volume
# here to get the yearly figures, takes a simple average of daily figures
multpl_stocks_yearly <- multpl_stocks %>%
  group_by(symbol, year = lubridate::year(date)) %>%
  summarise(adjusted_yearly = mean(adjusted),
            volume_yearly = sum(volume))

# Add market_value_equity column, adjusted*volume=market value equity
multpl_stocks_yearly <- multpl_stocks_yearly %>%
  mutate(market_value_equity = adjusted_yearly * volume_yearly)

# Calculate a scaling factor (e.g., 1 million) to reduce all equity values
scaling_factor <- 1e6
multpl_stocks_yearly <- multpl_stocks_yearly %>%
  mutate(scaled_market_value_equity = market_value_equity / scaling_factor)

#To get the yearly standard deviation = equity volatility
multpl_stock_monthly_returns <- multpl_stocks %>%
  group_by(symbol) %>%                        
  tq_transmute(select = adjusted,
               mutate_fun = periodReturn,
               period = 'monthly',
               type="log",
               col_rename = 'returns') 

multpl_stock_monthly_returns<-multpl_stock_monthly_returns %>%
  mutate(year = year(date)) %>%
  group_by(symbol, year) %>%
  summarise(sd = sd(returns))

# Add another column for adjusted standard deviation multiplied by sqrt(12)
#this is the annualised standard deviation which is needed.
multpl_stock_monthly_returns <- multpl_stock_monthly_returns %>%
  mutate(sd_times_sqrt_12 = sd * sqrt(12))

# Merge the two tables of s.d = volatility and adjusted price & volume
merged_table <- multpl_stocks_yearly %>%
  left_join(multpl_stock_monthly_returns, by = c("symbol", "year")) %>%
  rename(equity_volatility = sd_times_sqrt_12)

# Now we have set up a table containing all symbols, adj price, volume,
# equity_value, scaled_equity_value, equity_volatility

# We have a data.frame where we can automatically take the values
# of debt for each symbol and use the values of equity_volatility and scaled
# equity_value from the merged table to calculate the dtd function
# for each yr for each symbol

# Create a dataframe to store debt data for each company
debt_data <- data.frame(
  symbol= c("VALE","PBR","ITUB","ABCB","EC","AMX","CX","BVN","TV","YPF","MELI",
            "BBD","BRFS","GGB","ABEV",
            "TGS","BBVA","TEO","BMA",
            "FMX",
            "CIB",
            "SCCO",
            "SQM","BAP"),  # Specify symbols for each company
  debt_2008 = c(17535,10421,33812.5,120,739,4966.9,603,750,1107,749.5,1.5,8171.9,
                1155,4995.51,2295.36,
                225.809,84680.2,6.12,123.15,
                1595.62,
                1121.331,
                645.73,
                285.95,927.89),
  debt_2009 = c(10325,24622,14988.75,22.1345,1342.87,3895,7569.34,75.275,1603.005,288.04,3,6911.24,
                1495.51,3345.6645,1641.855,
                202.21,82153.8,7.805,157.95,
                1249.305,
                1043.405,
                635.126,
                512.175,1191.4865),
  debt_2010 = c(11437.5,30266,24192.785,42.882,2075.93,11898.5,7808.36,90,1855.07,206.785,0.09,6818.69,
                1419.92,3703.624,1188.46,
                190.645,68120.6,15.51,156.215,
                849.645,
                2067.505,
                1375.2005,
                525.094,1490.959),
  debt_2011 = c(11437,36408,16461.28,31.1345,2191.74,12650.5,9532.64,90,2259.48,564.995,0.068,8613.06,
                1381.925,3582.135,567.72,
                195.425,67793.85,13.96,158.14,
                861.5,
                2834.97,
                1367.866,
                618.5135,1982.761),  
  debt_2012 = c(14226,4285,43526.6,21.1345,3210.672,15528.5,7912.565,86.74,2174.485,1335.84,0.03,25403.635,
                1821.755,3110.9885,593.56,
                204.625,63689.6,11.15,81.715,
                1104.5,
                3376.58,
                2101.9315,
                723.097,2391.694),
  debt_2013 = c(14722.5,53154,42748.595,125.019,5784.48,17760,7340.57,111.5135,2521.325,2125.295,1.245,27082.605,
                1744.285,3465.0825,431.958,
                171.505,49596.065,20.26,154.23,
                2783.5,
                3328.63,
                2102.4575,
                708.695,2528.3575),
  debt_2014 = c(14557,60137,41838.65,72.103,8464.915,18547,8212.215,156.677,3213.59,2232.055,141.09,226606.08,
                1890.89,3135.3745,349.2325,
                133.835,47981.75,15.735,79.685,
                2811.5,
                2859.5785,
                1990.45,
                787.1125,2702.2115), 
  debt_2015 = c(13173.5,55780,38285.23,54.437,9729.94,16378.5,7975.62,160.158,3562.091,4239.609,147.171,23252.385,
                1915.926,3674.838,353.675,
                157.1605, 45678.525,78.8255,106.4945,
                2500,
                3887.173,
                2975.75,
                645.1015,2597.1155),
  debt_2016 = c(13831,54298.5,33217.315,288.274,31262.285,15078.5,6994.48,276.116,3634.44,4318.177,150.97,20066.455,
                2253.0895,2311.5205,253.113,
                127.669,42258.29,292.667,216.9055,
                3200.5,
                2805.7215,
                2977.1,
                546.719,2361.452),
  debt_2017 = c(10393,51124.5,35720.145,168.052,28802.5,16327.5,5031.845,274.546,3432.827,4582.155,156.09,12368.95,
                2413.676,2271.521,192.9155,
                95.727,36121.565,273.038,229.216,
                2998,
                2947.307,
                2978.55,
                515.7535,2351.8645),  
  debt_2018 = c(7231.5,40335,31278.5,120.4805,27234.17,13786,5429,270.448,3306.739,4796.973,301.114,13924.71,
                2410.156,1789.587,117.9355,
                357.7375,35819.28,1208.0105,437.781,
                2928,
                3043.085,
                2980.05,
                665.191,2351.8645),
  debt_2019 = c(7996,38457.5,35362.73,763.134,23258.87,13135.5,5173.5,152.998,3342.31,4761.4345,315.67,13177.48,
                1962.3615,1911.8235,305.309,
                329.7585,35819.28,1208.0105,332.054,
                2697.5,
                2988.2275,
                3270.5,
                744.3615,2239.7125),
  debt_2020 = c(8652,32827,28551.27,274.75,27175.46,12038.5,5063.5,253.283,3047.34,3917.4035,430.43, 5724.775,
                20704.11,1620.735,199.1895,
                304.822,35285.65,1126.046,285.0385,
                4521,
                2868.989,
                3272.1,
                949.7565, 2334.491)
)



# Print the debt data frame
print(debt_data)

# Create an empty dataframe to store results for all symbols
all_results <- data.frame(symbol = character(),
                          year = integer(),
                          dtd.v = numeric(),
                          asset.v = numeric(),
                          sigma.v = numeric(),
                          pd = numeric(),
                          stringsAsFactors = FALSE)

# Loop through each symbol
for (sym in unique(merged_table$symbol)) {
  # Filter the merged table to include only data for the current symbol
  symbol_data <- merged_table %>% filter(symbol == sym)
  
  # Get input debt values for the current symbol
  symbol_debt <- debt_data[debt_data$symbol == sym, ]
  debt_values <- c(symbol_debt$debt_2008, symbol_debt$debt_2009, symbol_debt$debt_2010,
                   symbol_debt$debt_2011, symbol_debt$debt_2012, symbol_debt$debt_2013,
                   symbol_debt$debt_2014, symbol_debt$debt_2015, symbol_debt$debt_2016,
                   symbol_debt$debt_2017, symbol_debt$debt_2018, symbol_debt$debt_2019,
                   symbol_debt$debt_2020)
  
  # Create a dataframe to store results for the current symbol
  symbol_results <- data.frame(symbol = rep(sym, 13),
                               year = unique(symbol_data$year),
                               dtd.v = NA,
                               asset.v = NA,
                               sigma.v = NA,
                               pd = NA,
                               stringsAsFactors = FALSE)
  
  # Loop through each year to calculate DTD, asset.v, sigma.v, and pd for the current symbol
  for (i in 1:nrow(symbol_results)) {
    # Subset data for the current year
    year_data <- symbol_data %>% filter(year == symbol_results$year[i])
    
    # Apply the dtd function to calculate DTD, asset.v, sigma.v, and pd
    dtd_result <- dtd(mcap = year_data$scaled_market_value_equity,
                      debt = debt_values[i],
                      vol = year_data$equity_volatility,
                      r = 0.05)
    
    # Store results in symbol_results dataframe
    symbol_results$dtd.v[i] <- dtd_result$dtd.v
    symbol_results$asset.v[i] <- dtd_result$asset.v
    symbol_results$sigma.v[i] <- dtd_result$sigma.v
    symbol_results$pd[i] <- dtd_result$pd
  }
  
  # Combine results for the current symbol with all_results dataframe
  all_results <- rbind(all_results, symbol_results)
}

# Print the results for all symbols, this shows each symbol and its dtd.v
#asset.v,sigma.v and p.d over the years 2008-2020
print(all_results)

#Now this code below creates the probabilty of default correlation matrix
# Get unique symbols
symbols <- unique(all_results$symbol)

# Create an empty matrix to store correlations
default_corr_matrix <- matrix(nrow = length(symbols), ncol = length(symbols), dimnames = list(symbols, symbols))

# Loop through each pair of symbols
for (i in 1:length(symbols)) {
  for (j in 1:length(symbols)) {
    # Get PD values for each symbol
    pd1 <- all_results$pd[all_results$symbol == symbols[i]]
    pd2 <- all_results$pd[all_results$symbol == symbols[j]]
    
    # Calculate correlation coefficient
    correlation <- cor(pd1, pd2)
    
    # Store correlation coefficient in the matrix
    default_corr_matrix[i, j] <- correlation
  }
}

# Print default correlation matrix
print(default_corr_matrix)

#need to adjust default correlation matrix, to get all correlations closer to some global average
default_corr_matrix
L2<-estimate.lambda(default_corr_matrix,verbose = TRUE)
L2
adj_default_corr_matrix<-cor.shrink(default_corr_matrix,lambda =L2)
adj_default_corr_matrix

#now to apply the filters to the adjusted default corr matrix to get specific corr
#coefficients by getting a simple average ie an average over companies.

# Initialize a matrix of zeros with the same dimensions as the correlation matrix
filtered_default_corr_global <- matrix(0, nrow = nrow(adj_default_corr_matrix), ncol = ncol(adj_default_corr_matrix))

# Loop through each row of the correlation matrix
for (i in 1:nrow(adj_default_corr_matrix)) {
  for (j in 1:ncol(adj_default_corr_matrix)) {
    # Get the symbols of the corresponding companies
    symbol1 <- rownames(adj_default_corr_matrix)[i]
    symbol2 <- colnames(adj_default_corr_matrix)[j]
    
    # Get the country and sector information for each company
    country1 <- company_info$Country[company_info$symbol == symbol1]
    country2 <- company_info$Country[company_info$symbol == symbol2]
    sector1 <- company_info$Sector[company_info$symbol == symbol1]
    sector2 <- company_info$Sector[company_info$symbol == symbol2]
    
    # Check if the companies are from different countries and sectors
    if (country1 != country2 & sector1 != sector2) {
      # Keep the correlation value unchanged
      filtered_default_corr_global[i, j] <- adj_default_corr_matrix[i, j]
    }
  }
}

# Print the filtered correlation matrix
print(filtered_default_corr_global)

#calculate simple average ie average over companies
non_empty_cells <- sum(filtered_default_corr_global != 0, na.rm = TRUE)
sum_of_default_correlations <- sum(filtered_default_corr_global, na.rm = TRUE)
avg_default_correlation_global <- sum_of_default_correlations / non_empty_cells

print(avg_default_correlation_global)
#This is the average correlation for global i.e different country, different sector

#///////////////////////////////////////////////////////////////////////////////

#This is for average country correlation coefficient ie same country, different sector
# Initialize a matrix of zeros with the same dimensions as the correlation matrix
filtered_default_corr_country <- matrix(0, nrow = nrow(adj_default_corr_matrix), ncol = ncol(adj_default_corr_matrix))

# Loop through each row of the correlation matrix
for (i in 1:nrow(adj_default_corr_matrix)) {
  for (j in 1:ncol(adj_default_corr_matrix)) {
    # Get the symbols of the corresponding companies
    symbol1 <- rownames(adj_default_corr_matrix)[i]
    symbol2 <- colnames(adj_default_corr_matrix)[j]
    
    # Get the country and sector information for each company
    country1 <- company_info$Country[company_info$symbol == symbol1]
    country2 <- company_info$Country[company_info$symbol == symbol2]
    sector1 <- company_info$Sector[company_info$symbol == symbol1]
    sector2 <- company_info$Sector[company_info$symbol == symbol2]
    
    # Check if the companies are from the same country but different sectors
    if (country1 == country2 & sector1 != sector2) {
      # Keep the correlation value unchanged
      filtered_default_corr_country[i, j] <- adj_default_corr_matrix[i, j]
    }
  }
}

# Print the filtered correlation matrix
print(filtered_default_corr_country)

# Calculate the simple average correlation over non-empty cells
non_empty_cells_country <- sum(filtered_default_corr_country != 0, na.rm = TRUE)
sum_of_default_correlations_country <- sum(filtered_default_corr_country, na.rm = TRUE)
avg_default_correlation_country <- sum_of_default_correlations_country / non_empty_cells_country

print(avg_default_correlation_country)

#/////////////////////////////////////////////////////////////////////////////////////////
#The average Financial correlation Coefficient, ie same country, any financial sector
#Initialize a matrix of zeros with the same dimensions as the correlation matrix
filtered_default_corr_financial <- matrix(0, nrow = nrow(adj_default_corr_matrix), ncol = ncol(adj_default_corr_matrix))

# Loop through each row of the correlation matrix
for (i in 1:nrow(adj_default_corr_matrix)) {
  for (j in 1:ncol(adj_default_corr_matrix)) {
    # Get the symbols of the corresponding companies
    symbol1 <- rownames(adj_default_corr_matrix)[i]
    symbol2 <- colnames(adj_default_corr_matrix)[j]
    
    # Get the country and sector information for each company
    country1 <- company_info$Country[company_info$symbol == symbol1]
    country2 <- company_info$Country[company_info$symbol == symbol2]
    sector1 <- company_info$Sector[company_info$symbol == symbol1]
    sector2 <- company_info$Sector[company_info$symbol == symbol2]
    fsector1 <- company_info$Fsector[company_info$symbol == symbol1]
    fsector2 <- company_info$Fsector[company_info$symbol == symbol2]
    
    # Check if the companies are from the same country and belong to the financial sector
    if (symbol1 != symbol2 & country1 == country2 & fsector1 == "Financial" & fsector2 == "Financial") {
      # Keep the correlation value unchanged
      filtered_default_corr_financial[i, j] <- adj_default_corr_matrix[i, j]
    }
  }
}

# Print the filtered correlation matrix
print(filtered_default_corr_financial)

# Calculate the simple average correlation over non-empty cells
non_empty_cells_financial <- sum(filtered_default_corr_financial != 0, na.rm = TRUE)
sum_of_default_correlations_financial <- sum(filtered_default_corr_financial, na.rm = TRUE)
avg_default_correlation_financial <- sum_of_default_correlations_financial / non_empty_cells_financial

print(avg_default_correlation_financial)

#/////////////////////////////////////////////////////////////////////////////////////////////
#Non-financial correlation coefficient, same country, any non-financial sector
# Initialize a matrix of zeros with the same dimensions as the correlation matrix
filtered_default_corr_non_financial <- matrix(0, nrow = nrow(adj_default_corr_matrix), ncol = ncol(adj_default_corr_matrix))

# Loop through each row of the correlation matrix
for (i in 1:nrow(adj_default_corr_matrix)) {
  for (j in 1:ncol(adj_default_corr_matrix)) {
    # Get the symbols of the corresponding companies
    symbol1 <- rownames(adj_default_corr_matrix)[i]
    symbol2 <- colnames(adj_default_corr_matrix)[j]
    
    # Get the country and sector information for each company
    country1 <- company_info$Country[company_info$symbol == symbol1]
    country2 <- company_info$Country[company_info$symbol == symbol2]
    sector1 <- company_info$Sector[company_info$symbol == symbol1]
    sector2 <- company_info$Sector[company_info$symbol == symbol2]
    fsector1 <- company_info$Fsector[company_info$symbol == symbol1]
    fsector2 <- company_info$Fsector[company_info$symbol == symbol2]
    
    # Check if the companies are from the same country and belong to the non-financial sector
    if (symbol1 != symbol2 & country1 == country2 & fsector1 == "Non_Financial" & fsector2 == "Non_Financial") {
      # Keep the correlation value unchanged
      filtered_default_corr_non_financial[i, j] <- adj_default_corr_matrix[i, j]
    }
  }
}

# Print the filtered correlation matrix
print(filtered_default_corr_non_financial)

# Calculate the simple average correlation over non-empty cells
non_empty_cells_non_financial <- sum(filtered_default_corr_non_financial != 0, na.rm = TRUE)
sum_of_default_correlations_non_financial <- sum(filtered_default_corr_non_financial, na.rm = TRUE)
avg_default_correlation_non_financial <- sum_of_default_correlations_non_financial / non_empty_cells_non_financial

print(avg_default_correlation_non_financial)

#if says NaN, that's true as in the current stocks there is no pairs that match this
#//////////////////////////////////////////////////////////////////////////////////////

#Now to get average over time for p.d.

# Define the fixed window size
window_size <- 3

# Define a list to store the rolling correlation matrices for each window size
rolling_corr_list_pd <- list()

# Loop through each pair of symbols
for (i in 1:(length(tickers) - 1)) {
  for (j in (i + 1):length(tickers)) {
    # Combine p.d values for the current pair of symbols into a single data frame
    pd_df <- merge(
      all_results %>% filter(symbol == tickers[i]),
      all_results %>% filter(symbol == tickers[j]),
      by = "year", suffixes = c(paste0("_", tickers[i]), paste0("_", tickers[j]))
    )
    
    # Convert data to zoo object for rolling calculations
    zoo_data_pd <- zoo(pd_df[, c(paste0("pd_", tickers[i]), paste0("pd_", tickers[j]))], 
                       order.by = pd_df$year)
    
    # Calculate rolling correlation
    rolling_corr_pd <- rollapply(zoo_data_pd, width = window_size, function(x) cor(x[, 1], x[, 2]), by.column = FALSE)
    
    # Store the rolling correlation in the list
    corr_key_pd <- paste(tickers[i], tickers[j], sep = "_vs_")
    rolling_corr_list_pd[[corr_key_pd]] <- rolling_corr_pd
  }
}

# Print the list of rolling correlation matrices for p.d values
print(rolling_corr_list_pd)

#rolling_corr_list_pd shows us the rolling correlations of default probabililty ie correlations over time
# for all pairs of symbols. We can stop here for an 'average over time'

# Initialize an empty list to store multiple correlation matrices for p.d values
corr_matrix_list_pd <- list()

# Loop through each entry in the rolling correlation list for p.d values
for (k in 1:length(rolling_corr_list_pd)) {
  # Initialize an empty matrix to store the rolling correlation coefficients for p.d values
  corr_matrix_pd <- matrix(NA, nrow = length(tickers), ncol = length(tickers))
  rownames(corr_matrix_pd) <- tickers
  colnames(corr_matrix_pd) <- tickers
  
  # Loop through each pair of symbols
  for (i in 1:length(tickers)) {
    for (j in 1:length(tickers)) {
      # Define the key for accessing the rolling correlation list for p.d values
      corr_key_pd <- paste(tickers[i], tickers[j], sep = "_vs_")
      
      # Check if the rolling correlation list exists for the current pair of symbols for p.d values
      if (corr_key_pd %in% names(rolling_corr_list_pd)) {
        # Extract the rolling correlation for the current entry from the rolling_corr_list_pd
        rolling_corr_pd <- rolling_corr_list_pd[[corr_key_pd]]
        
        # Store the rolling correlation in the matrix for p.d values
        corr_matrix_pd[i, j] <- rolling_corr_pd[k]
      } else {
        # If no rolling correlation is available, set the corresponding matrix entry to NA for p.d values
        corr_matrix_pd[i, j] <- NA
      }
    }
  }
  
  # Append the correlation matrix for p.d values to the list
  corr_matrix_list_pd[[k]] <- corr_matrix_pd
}

# Print the list of correlation matrices for p.d values
print(corr_matrix_list_pd)

#corr_matrix_list_pd creates multiple matrices where each one contains values for the nth rolling corr
# for all pairs of symbols, therefore the code below for sum_matrix_pd averages these matrixes, to get 
# a single matrix that has the average correlation over time (ie an average of the rolling correlations)
# for every combination of symbols.

# Initialize an empty matrix to store the sum of matrices for p.d values
sum_matrix_pd <- matrix(0, nrow = length(tickers), ncol = length(tickers))

# Initialize a flag variable to track whether we've encountered the first NA matrix for p.d values
encountered_na_pd <- FALSE

# Loop through each matrix in the list for p.d values
for (i in 1:(length(corr_matrix_list_pd) - 1)) {
  # Check if the current matrix is entirely NA for p.d values
  if (all(is.na(corr_matrix_list_pd[[i]]))) {
    # If it is, set the flag variable to TRUE and break the loop for p.d values
    encountered_na_pd <- TRUE
    break
  }
  # If we haven't encountered an NA matrix yet for p.d values, add the current matrix to the sum matrix for p.d values
  sum_matrix_pd <- sum_matrix_pd + corr_matrix_list_pd[[i]]
}

# If we encountered an NA matrix for p.d values, divide the sum matrix by the number of matrices added for p.d values
if (encountered_na_pd) {
  sum_matrix_pd <- sum_matrix_pd / (i - 1)
} else {
  # If no NA matrix was encountered for p.d values, divide by the total number of matrices for p.d values
  sum_matrix_pd <- sum_matrix_pd / i
}

# Print the resulting sum matrix for p.d values
print(sum_matrix_pd)

# Add a leading diagonal of 1 for p.d values
diag(sum_matrix_pd) <- 1

# Make the matrix symmetrical below the leading 1 for p.d values
for (i in 1:(length(tickers) - 1)) {
  for (j in (i + 1):length(tickers)) {
    sum_matrix_pd[j, i] <- sum_matrix_pd[i, j]
  }
}

# Print the updated final correlation matrix for p.d values
print(sum_matrix_pd)

#Now we can shrink this matrix and apply the filters to get the specific matrixes for each correlation
# coefficient.

# So to shrink

L4<-estimate.lambda(sum_matrix_pd,verbose = TRUE)
L4
shrunk_sum_matrix_pd<-cor.shrink(sum_matrix_pd,lambda =L4)
shrunk_sum_matrix_pd

#now to apply filtering

#Now to this shrunk_sum_matrix you can apply filtering to get identify specific
#average default correlations over time eg global, country, financial, non-financial. Where
#each one is called aot_filtered_default_corr_type, aot=average over time.

# Initialize a matrix of zeros with the same dimensions as the correlation matrix
aot_filtered_default_corr_global <- matrix(0, nrow = nrow(shrunk_sum_matrix_pd), ncol = ncol(shrunk_sum_matrix_pd))

# Loop through each row of the correlation matrix
for (i in 1:nrow(shrunk_sum_matrix_pd)) {
  for (j in 1:ncol(shrunk_sum_matrix_pd)) {
    # Get the symbols of the corresponding companies
    symbol1 <- rownames(shrunk_sum_matrix_pd)[i]
    symbol2 <- colnames(shrunk_sum_matrix_pd)[j]
    
    # Get the country and sector information for each company
    country1 <- company_info$Country[company_info$symbol == symbol1]
    country2 <- company_info$Country[company_info$symbol == symbol2]
    sector1 <- company_info$Sector[company_info$symbol == symbol1]
    sector2 <- company_info$Sector[company_info$symbol == symbol2]
    
    # Check if the companies are from different countries and sectors
    if (country1 != country2 & sector1 != sector2) {
      # Keep the correlation value unchanged
      aot_filtered_default_corr_global[i, j] <- shrunk_sum_matrix_pd[i, j]
    }
  }
}

# Print the filtered default correlation matrix
print(aot_filtered_default_corr_global)

#This is the average default correlation over time for global i.e different country, different sector

#///////////////////////////////////////////////////////////////////////////////

#This is for average country correlation coefficient ie same country, different sector
# Initialize a matrix of zeros with the same dimensions as the correlation matrix
aot_filtered_default_corr_country <- matrix(0, nrow = nrow(shrunk_sum_matrix_pd), ncol = ncol(shrunk_sum_matrix_pd))

# Loop through each row of the correlation matrix
for (i in 1:nrow(shrunk_sum_matrix_pd)) {
  for (j in 1:ncol(shrunk_sum_matrix_pd)) {
    # Get the symbols of the corresponding companies
    symbol1 <- rownames(shrunk_sum_matrix_pd)[i]
    symbol2 <- colnames(shrunk_sum_matrix_pd)[j]
    
    # Get the country and sector information for each company
    country1 <- company_info$Country[company_info$symbol == symbol1]
    country2 <- company_info$Country[company_info$symbol == symbol2]
    sector1 <- company_info$Sector[company_info$symbol == symbol1]
    sector2 <- company_info$Sector[company_info$symbol == symbol2]
    
    # Check if the companies are from the same country but different sectors
    if (country1 == country2 & sector1 != sector2) {
      # Keep the correlation value unchanged
      aot_filtered_default_corr_country[i, j] <- shrunk_sum_matrix_pd[i, j]
    }
  }
}

# Print the filtered default correlation matrix
print(aot_filtered_default_corr_country)

#/////////////////////////////////////////////////////////////////////////////////////////
#The average Financial correlation Coefficient, ie same country, any financial sector
#Initialize a matrix of zeros with the same dimensions as the correlation matrix
aot_filtered_default_corr_financial <- matrix(0, nrow = nrow(shrunk_sum_matrix_pd), ncol = ncol(shrunk_sum_matrix_pd))

# Loop through each row of the correlation matrix
for (i in 1:nrow(shrunk_sum_matrix_pd)) {
  for (j in 1:ncol(shrunk_sum_matrix_pd)) {
    # Get the symbols of the corresponding companies
    symbol1 <- rownames(shrunk_sum_matrix_pd)[i]
    symbol2 <- colnames(shrunk_sum_matrix_pd)[j]
    
    # Get the country and sector information for each company
    country1 <- company_info$Country[company_info$symbol == symbol1]
    country2 <- company_info$Country[company_info$symbol == symbol2]
    sector1 <- company_info$Sector[company_info$symbol == symbol1]
    sector2 <- company_info$Sector[company_info$symbol == symbol2]
    fsector1 <- company_info$Fsector[company_info$symbol == symbol1]
    fsector2 <- company_info$Fsector[company_info$symbol == symbol2]
    
    # Check if the companies are from the same country and belong to the financial sector
    if (symbol1 != symbol2 & country1 == country2 & fsector1 == "Financial" & fsector2 == "Financial") {
      # Keep the correlation value unchanged
      aot_filtered_default_corr_financial[i, j] <- shrunk_sum_matrix_pd[i, j]
    }
  }
}

# Print the filtered default correlation matrix
print(aot_filtered_default_corr_financial)

#/////////////////////////////////////////////////////////////////////////////////////////////
#Non-financial correlation coefficient, same country, any non-financial sector
# Initialize a matrix of zeros with the same dimensions as the correlation matrix
aot_filtered_default_corr_non_financial <- matrix(0, nrow = nrow(shrunk_sum_matrix_pd), ncol = ncol(shrunk_sum_matrix_pd))

# Loop through each row of the correlation matrix
for (i in 1:nrow(shrunk_sum_matrix_pd)) {
  for (j in 1:ncol(shrunk_sum_matrix_pd)) {
    # Get the symbols of the corresponding companies
    symbol1 <- rownames(shrunk_sum_matrix_pd)[i]
    symbol2 <- colnames(shrunk_sum_matrix_pd)[j]
    
    # Get the country and sector information for each company
    country1 <- company_info$Country[company_info$symbol == symbol1]
    country2 <- company_info$Country[company_info$symbol == symbol2]
    sector1 <- company_info$Sector[company_info$symbol == symbol1]
    sector2 <- company_info$Sector[company_info$symbol == symbol2]
    fsector1 <- company_info$Fsector[company_info$symbol == symbol1]
    fsector2 <- company_info$Fsector[company_info$symbol == symbol2]
    
    # Check if the companies are from the same country and belong to the non-financial sector
    if (symbol1 != symbol2 & country1 == country2 & fsector1 == "Non_Financial" & fsector2 == "Non_Financial") {
      # Keep the correlation value unchanged
      aot_filtered_default_corr_non_financial[i, j] <- shrunk_sum_matrix_pd[i, j]
    }
  }
}

# Print the filtered default correlation matrix
print(aot_filtered_default_corr_non_financial)

#Now after getting the sum matrix, applying James Steinz, we've successfully filtered each
#matrix to see the average default correlation over time.

#////////////////////////////////////////////////////////////////////////////////////////////////////////

#Now for significance testing, here you can input any matrix into the function created to
# test for significance

test_correlation_matrix <- function(corr_matrix, alpha = 0.05) {
  # Initialize a matrix to store results
  results <- matrix(NA, nrow = nrow(corr_matrix), ncol = ncol(corr_matrix))
  rownames(results) <- colnames(corr_matrix)
  colnames(results) <- colnames(corr_matrix)
  
  # Loop through each correlation coefficient
  for (i in 1:nrow(corr_matrix)) {
    for (j in 1:ncol(corr_matrix)) {
      # Calculate test statistic (Pearson correlation coefficient) and p-value
      corr <- corr_matrix[i, j]
      # Calculate the degrees of freedom
      n <- length(corr_matrix)
      df <- n - 2
      # Calculate the t-statistic
      t_stat <- corr * sqrt(df / (1 - corr^2))
      # Calculate the p-value using the t-distribution
      p_value <- 2 * pt(-abs(t_stat), df)
      # Store results
      if (p_value < alpha) {
        results[i, j] <- "Reject H0"  # Reject null hypothesis
      } else {
        results[i, j] <- "Fail to reject H0"  # Fail to reject null hypothesis
      }
    }
  }
  
  # Return the results
  return(results)
}

#as an example
test_correlation_matrix(aot_filtered_corr_global,alpha=0.05)

#could add a correction such as Bonferri Correction but then the alpha becomes too small
# and the H0 is always rejected. May seem like a large amount of failure to reject but
# remeber the filtered matrixes have a lot of 0's.




